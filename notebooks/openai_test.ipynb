{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8ffa8d",
   "metadata": {},
   "source": [
    "## Initialise client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbd2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051166ab",
   "metadata": {},
   "source": [
    "## Select Model and test response\n",
    "For models with low latency and good performance, currently options are\n",
    "- `o4-mini`\n",
    "- `4o`\n",
    "\n",
    "So we can try using o4 due to its \"Thinking\" capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723a3270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_685bca8504e4819e9c1ee656fd38b11f0a31a9fa834814ee', created_at=1750846085.0, error=None, incomplete_details=None, instructions='\\n    You are Auricue, a real-time audio coach for users in conversation.\\n    Given a brief transcript of what just happened, you will:\\n    1. Identify up to three concise factual observations (e.g., mood, topic shifts, speaker tone).\\n    2. Suggest one strategic cue (e.g., ask an open question, mirror emotion, introduce a relevant fact) less than 12 words long.\\n    Return exactly a JSON object with two keys: \"facts\" (array of strings) and \"strategy\" (string).\\n    If the provided transcript is too short or lacks context to produce these, respond with the JSON:\\n    {\"facts\": [], \"strategy\": \"need more data\"}\\n    and nothing else.\\n', metadata={}, model='o4-mini-2025-04-16', object='response', output=[ResponseReasoningItem(id='rs_685bca855b6c819e916a9621943a5c430a31a9fa834814ee', summary=[], type='reasoning', encrypted_content=None, status=None), ResponseOutputMessage(id='msg_685bca87bdec819e9fa9bc5ee5969b480a31a9fa834814ee', content=[ResponseOutputText(annotations=[], text='{\"facts\":[\"Informal language used by speakers (“broski”, “bruh”)\",\"A expresses uncertainty through pauses and filler words\",\"Participants disagree on whether users like the prototype\"],\"strategy\":\"Request specific user feedback on the prototype\"}', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=1000, previous_response_id=None, prompt=None, reasoning=Reasoning(effort='low', generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=309, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=373, output_tokens_details=OutputTokensDetails(reasoning_tokens=320), total_tokens=682), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are Auricue, a real-time audio coach for users in conversation.\n",
    "    Given a brief transcript of what just happened, you will:\n",
    "    1. Identify up to three concise factual observations (e.g., mood, topic shifts, speaker tone).\n",
    "    2. Suggest one strategic cue (e.g., ask an open question, mirror emotion, introduce a relevant fact) less than 12 words long.\n",
    "    Return exactly a JSON object with two keys: \"facts\" (array of strings) and \"strategy\" (string).\n",
    "    If the provided transcript is too short or lacks context to produce these, respond with the JSON:\n",
    "    {\"facts\": [], \"strategy\": \"need more data\"}\n",
    "    and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "input = [\n",
    "    {\"role\": \"user\", \"content\": \"A: So yeah uh I think we can [Pause] uh\"},\n",
    "    {\"role\": \"user\", \"content\": \"User: What are you yapping about broski\"},\n",
    "    {\"role\": \"user\", \"content\": \"A: Nothing it's just maybe it isn't the greatest idea in my opinion\"},\n",
    "    {\"role\": \"user\", \"content\": \"B: And why do you think that bruh, look this is super\"},\n",
    "    {\"role\": \"user\", \"content\": \"A: Yeah but\"},\n",
    "    {\"role\": \"user\", \"content\": \"B: cool and I'm totally in for that [Pause] I mean well we still don't have to do it now right\"},\n",
    "    {\"role\": \"user\", \"content\": \"User: Can't we think about the prototype though, i mean\"},\n",
    "    {\"role\": \"user\", \"content\": \"A: No the users don't like it\"},\n",
    "    {\"role\": \"user\", \"content\": \"User: uh thats what you'd think but actually i think they are fine with it no?\"}\n",
    "]\n",
    "\n",
    "model = \"o4-mini\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=model,\n",
    "    input=input,\n",
    "    instructions=system_prompt,\n",
    "    max_output_tokens=1000,\n",
    "    reasoning={\"effort\": \"low\"}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c738b88",
   "metadata": {},
   "source": [
    "## Read the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"facts\":[\"Informal language used by speakers (“broski”, “bruh”)\",\"A expresses uncertainty through pauses and filler words\",\"Participants disagree on whether users like the prototype\"],\"strategy\":\"Request specific user feedback on the prototype\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
